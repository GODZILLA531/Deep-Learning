{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3DR-eO17geWu"
      },
      "source": [
        "# Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "EMefrVPCg-60"
      },
      "source": [
        "### Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sCV30xyVhFbE"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-05 23:19:07.946180: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-11-05 23:19:08.378046: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:08.378080: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
            "2022-11-05 23:19:08.445637: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2022-11-05 23:19:09.944995: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:09.946007: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:09.946019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "FIleuCAjoFD8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'2.10.0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "oxQxCBWyoGPE"
      },
      "source": [
        "## Part 1 - Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MvE-heJNo3GG"
      },
      "source": [
        "### Preprocessing the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0koUcJMJpEBD"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "mrCMmGw9pHys"
      },
      "source": [
        "### Preprocessing the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SH4WzfOhpKc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "af8O4l90gk7B"
      },
      "source": [
        "## Part 2 - Building the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ces1gXY2lmoX"
      },
      "source": [
        "### Initialising the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SAUt4UMPlhLS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-05 23:19:40.110815: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-11-05 23:19:40.112683: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:40.112997: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:40.113188: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:40.113372: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:40.113542: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:40.113709: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:40.113874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:40.114041: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
            "2022-11-05 23:19:40.114056: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n",
            "2022-11-05 23:19:40.118239: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "u5YJj_XMl5LF"
      },
      "source": [
        "### Step 1 - Convolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XPzPrMckl-hV"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tf87FpvxmNOJ"
      },
      "source": [
        "### Step 2 - Pooling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ncpqPl69mOac"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "xaTOgD8rm4mU"
      },
      "source": [
        "### Adding a second convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "i_-FZjn_m8gk"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "tmiEuvTunKfk"
      },
      "source": [
        "### Step 3 - Flattening"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "6AZeOGCvnNZn"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dAoSECOm203v"
      },
      "source": [
        "### Step 4 - Full Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "8GtmUlLd26Nq"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yTldFvbX28Na"
      },
      "source": [
        "### Step 5 - Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1p_Zj1Mc3Ko_"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D6XkI90snSDl"
      },
      "source": [
        "## Part 3 - Training the CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "vfrFQACEnc6i"
      },
      "source": [
        "### Compiling the CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "NALksrNQpUlJ"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ehS-v3MIpX2h"
      },
      "source": [
        "### Training the CNN on the Training set and evaluating it on the Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XUj1W4PJptta"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "  2/250 [..............................] - ETA: 31s - loss: 0.9217 - accuracy: 0.4688 "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-05 23:45:30.630640: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28096128 exceeds 10% of free system memory.\n",
            "2022-11-05 23:45:30.635580: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28096128 exceeds 10% of free system memory.\n",
            "2022-11-05 23:45:30.761157: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28096128 exceeds 10% of free system memory.\n",
            "2022-11-05 23:45:30.761531: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28096128 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  3/250 [..............................] - ETA: 35s - loss: 0.8646 - accuracy: 0.4792"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-05 23:45:30.916227: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28096128 exceeds 10% of free system memory.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "250/250 [==============================] - 38s 150ms/step - loss: 0.6858 - accuracy: 0.5481 - val_loss: 0.6488 - val_accuracy: 0.6160\n",
            "Epoch 2/25\n",
            "250/250 [==============================] - 35s 142ms/step - loss: 0.6210 - accuracy: 0.6562 - val_loss: 0.6313 - val_accuracy: 0.6465\n",
            "Epoch 3/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.5643 - accuracy: 0.7097 - val_loss: 0.5398 - val_accuracy: 0.7375\n",
            "Epoch 4/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.5282 - accuracy: 0.7315 - val_loss: 0.5220 - val_accuracy: 0.7475\n",
            "Epoch 5/25\n",
            "250/250 [==============================] - 34s 134ms/step - loss: 0.5030 - accuracy: 0.7519 - val_loss: 0.5594 - val_accuracy: 0.7205\n",
            "Epoch 6/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.4855 - accuracy: 0.7663 - val_loss: 0.4774 - val_accuracy: 0.7685\n",
            "Epoch 7/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.4691 - accuracy: 0.7775 - val_loss: 0.4690 - val_accuracy: 0.7865\n",
            "Epoch 8/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.4474 - accuracy: 0.7889 - val_loss: 0.4901 - val_accuracy: 0.7705\n",
            "Epoch 9/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.4296 - accuracy: 0.8008 - val_loss: 0.4544 - val_accuracy: 0.7850\n",
            "Epoch 10/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.4204 - accuracy: 0.8080 - val_loss: 0.4728 - val_accuracy: 0.7785\n",
            "Epoch 11/25\n",
            "250/250 [==============================] - 34s 134ms/step - loss: 0.3988 - accuracy: 0.8146 - val_loss: 0.4554 - val_accuracy: 0.7920\n",
            "Epoch 12/25\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 0.3930 - accuracy: 0.8199 - val_loss: 0.4754 - val_accuracy: 0.7790\n",
            "Epoch 13/25\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 0.3738 - accuracy: 0.8317 - val_loss: 0.5257 - val_accuracy: 0.7830\n",
            "Epoch 14/25\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 0.3541 - accuracy: 0.8438 - val_loss: 0.4566 - val_accuracy: 0.7965\n",
            "Epoch 15/25\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 0.3413 - accuracy: 0.8505 - val_loss: 0.4631 - val_accuracy: 0.7965\n",
            "Epoch 16/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.3260 - accuracy: 0.8602 - val_loss: 0.4495 - val_accuracy: 0.8050\n",
            "Epoch 17/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.3105 - accuracy: 0.8677 - val_loss: 0.5147 - val_accuracy: 0.7890\n",
            "Epoch 18/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.2881 - accuracy: 0.8752 - val_loss: 0.7195 - val_accuracy: 0.7310\n",
            "Epoch 19/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.2816 - accuracy: 0.8771 - val_loss: 0.4944 - val_accuracy: 0.7950\n",
            "Epoch 20/25\n",
            "250/250 [==============================] - 34s 135ms/step - loss: 0.2618 - accuracy: 0.8905 - val_loss: 0.6828 - val_accuracy: 0.7605\n",
            "Epoch 21/25\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 0.2536 - accuracy: 0.8923 - val_loss: 0.4873 - val_accuracy: 0.8040\n",
            "Epoch 22/25\n",
            "250/250 [==============================] - 34s 137ms/step - loss: 0.2373 - accuracy: 0.8996 - val_loss: 0.5129 - val_accuracy: 0.8035\n",
            "Epoch 23/25\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 0.2322 - accuracy: 0.9075 - val_loss: 0.5327 - val_accuracy: 0.7985\n",
            "Epoch 24/25\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 0.2127 - accuracy: 0.9145 - val_loss: 0.5581 - val_accuracy: 0.8030\n",
            "Epoch 25/25\n",
            "250/250 [==============================] - 34s 136ms/step - loss: 0.1983 - accuracy: 0.9186 - val_loss: 0.5499 - val_accuracy: 0.8100\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3944a7940>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "U3PZasO0006Z"
      },
      "source": [
        "## Part 4 - Making a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "gsSiWEJY1BPB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 4s 55ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " True,\n",
              " True,\n",
              " False,\n",
              " False,\n",
              " False,\n",
              " ...]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = cnn.predict(test_set)\n",
        "training_set.class_indices\n",
        "y_pred=[]\n",
        "for i in range(len(result)):\n",
        "    y_pred.append(result[i][0]>0.5)     \n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ED9KB3I54c1i"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cat\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "convolutional_neural_network.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
